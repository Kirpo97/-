{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лабораторная работа №6: Реализация голосового ввода для управления функциями информационных систем"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание:\n",
    "1. Необходимо реализовать модуль, который записывает команду голосом с микрофона по умолчанию, превращает ее в текст, извлекает из текста ключевые слова, если находит в ключевых словах команду, выполняет ее.\n",
    "2. Для этого нужно создать виртуальную среду  `python -m venv ./venv`\n",
    "3. Установить библиотеку для записи аудио `pyaudio`: `python -m pip install pyaudio` ([PyAudio: Cross-platform audio I/O for Python, with PortAudio](https://people.csail.mit.edu/hubert/pyaudio/#docs))\n",
    "4. Установить платформу для распознавания речи Whisper ([GitHub - openai/whisper: Robust Speech Recognition via Large-Scale Weak Supervision](https://github.com/openai/whisper)): `pip install git+https://github.com/openai/whisper.git`\n",
    "5. Воспользовавшись наработками из лабораторной работы №4, реализовать препроцессинг голосовой команды и извлечение ключевых слов для вариантов ниже:\n",
    "    1. для генерации ссылки на поиск, например, в Яндексе произвольного текста в браузере по умолчанию\n",
    "    2. для открытия видеофайла из файловой системы в плеере по умолчанию или поиска видео на YouTube (или аналогичной платформе)\n",
    "    3. для запуска любого приложения для коммуникации (ВК, Телеграм, Дискорд и т.п.)\n",
    "6. Реализовать через `subprocess` или иные средства выполнение указанных команд\n",
    "\n",
    ">[!note]\n",
    ">Передавать в Whisper можно как .wav-файл, так и NumPy-массив\n",
    ">Но тут есть нюансы, поэтому рекомендую прочесть эти две ссылки: \n",
    ">- [How to send audio to Whisper in a numpy array ? · openai/whisper · Discussion #450 · GitHub](https://github.com/openai/whisper/discussions/450)\n",
    ">- [python - How to feed a numpy array as audio for whisper model - Stack Overflow](https://stackoverflow.com/questions/76448210/how-to-feed-a-numpy-array-as-audio-for-whisper-model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wave\n",
    "import sys\n",
    "import pyaudio\n",
    "import os\n",
    "import subprocess\n",
    "import webbrowser\n",
    "\n",
    "\n",
    "CHUNK = 1024\n",
    "FORMAT = pyaudio.paInt16\n",
    "CHANNELS = 1 if sys.platform == 'darwin' else 2\n",
    "RATE = 44100\n",
    "RECORD_SECONDS = 5\n",
    "\n",
    "try:   \n",
    "    with wave.open('output.wav', 'wb') as wf:\n",
    "        p = pyaudio.PyAudio()\n",
    "        wf.setnchannels(CHANNELS)\n",
    "        wf.setsampwidth(p.get_sample_size(FORMAT))\n",
    "        wf.setframerate(RATE)\n",
    "\n",
    "        stream = p.open(format=FORMAT, channels=CHANNELS, rate=RATE, input=True)\n",
    "\n",
    "        print('Recording...')\n",
    "        for _ in range(0, RATE // CHUNK * RECORD_SECONDS):\n",
    "            wf.writeframes(stream.read(CHUNK))\n",
    "        print('Done')\n",
    "\n",
    "        stream.close()\n",
    "        p.terminate()\n",
    "except:\n",
    "    print('error')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
